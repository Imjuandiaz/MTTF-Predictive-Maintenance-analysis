# -*- coding: utf-8 -*-
"""predictive_maintenance_clasf - OCT 2025

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fobeNzQBSBNJf0pSP6pLpnXg0vtVAMQs

#DataSet Mean Time Between Failure
#Autor: Juan Diaz
##Importing data For Machine Failure Predictive Maintenance
The objective of this project is to determinate whether a machine failure will occur within 30 days
"""

#code snippet #1
#importing tools for data analisys
import missingno as msno
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#code snippet 2
#reading and displaying data with pandas
data = pd.read_csv ('https://raw.githubusercontent.com/Imjuandiaz/MTTF-Predictive-Maintenance-analysis/refs/heads/main/Data/ai4i2020.csv')

data

#code snippet 3
#show data columns
data.columns

#code snipept 3.5
#displaying data type
data.dtypes

"""#Statistical analysis"""

#code snipep 4
#displaying statistical analisys
data.describe()

"""#Checking for Null/Missing Data"""

#code snippet 4.5
#displaying the proportion of missing data in the dataset
msno.bar(data)

#CodeSnippet 5
# Checking for missing values
data.isnull().sum()

"""#Distribution and Correlation Analysis"""

#CodeSnippet 6
# Checking the proportion of machine failures
data['Machine failure'].value_counts(normalize=True)

#CodeSnippet 7
# Correlation heatmap between numerical features
plt.figure(figsize=(10,6))
sns.heatmap(data.select_dtypes(include=np.number).corr(), cmap='coolwarm', annot=False)
plt.title('Correlation Heatmap')
plt.show()

#CodeSnippet 8
# Torque distribution depending on failure
plt.figure(figsize=(8,5))
sns.boxplot(x='Machine failure', y='Torque [Nm]', data=data)
plt.title('Torque Distribution vs Machine Failure')
plt.show()

"""#FEATURE ENGINEERING"""

#CodeSnippet 9
# Creating new derived features
data['Temp_diff'] = data['Process temperature [K]'] - data['Air temperature [K]']
data['Wear_per_torque'] = data['Tool wear [min]'] / data['Torque [Nm]']

# Displaying first rows of engineered features
data[['Temp_diff', 'Wear_per_torque']].head()

#CodeSnippet 10
# Creating simulated time index per product
data['time_index'] = data.groupby('Product ID').cumcount()

# Marking failure events
data['failure_event'] = data['Machine failure'].astype(bool)

# Calculating approximate MTBF per product
mtbf = data[data['failure_event']].groupby('Product ID')['time_index'].diff().mean()
print("Mean Time Between Failures (approx):", mtbf)

#CodeSnippet 11
# Sort data by Product ID and artificial time index
data = data.sort_values(['Product ID', 'time_index'])

# Extract only rows where a failure occurred
failures = data[data['Machine failure'] == 1].copy()

# Compute difference between consecutive failures (across all products)
failures['delta'] = failures['time_index'].diff()

# Calculate mean time between failures globally
mtbf_global = failures['delta'].mean()
print("Mean Time Between Failures (simulated global):", mtbf_global)

#CodeSnippet 12
# Approximate MTBF using tool wear data before each failure
mtbf_proxy = data[data['Machine failure'] == 1]['Tool wear [min]'].mean()
print("Approximate MTBF (using tool wear minutes):", mtbf_proxy, "minutes")

#CodeSnippet 13
# MTBF approximation by product type
mtbf_by_type = data[data['Machine failure'] == 1].groupby('Type')['Tool wear [min]'].mean()
print("MTBF Approximation per Type (in minutes):\n", mtbf_by_type)

#CodeSnippet 14
# Visualizing average wear before failure by product type
plt.figure(figsize=(8,5))
sns.barplot(x=mtbf_by_type.index, y=mtbf_by_type.values, palette="viridis")
plt.title("Mean Time Between Failures (approx) by Product Type")
plt.ylabel("Average Tool Wear before Failure [min]")
plt.xlabel("Product Type")
plt.show()

#CodeSnippet 15
# Selecting independent variables (features)
features = ['Air temperature [K]', 'Process temperature [K]',
            'Rotational speed [rpm]', 'Torque [Nm]',
            'Tool wear [min]', 'Temp_diff', 'Wear_per_torque']

X = data[features]
y = data['Machine failure']

"""#Model Classification Training"""

#CodeSnippet 16
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

# CodeSnippet 17 (Updated)
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.model_selection import StratifiedKFold, cross_val_score
import numpy as np

# Create SMOTE object
smote = SMOTE(random_state=42)

# Define model (class_weight removed because SMOTE already balances)
rf_clf = RandomForestClassifier(
    n_estimators=200,
    max_depth=15,
    random_state=42,
    n_jobs=-1
)

# Create pipeline with preprocessing + oversampling + model
clf_pipeline = ImbPipeline(steps=[
    ('smote', smote),
    ('model', rf_clf)
])

# Stratified cross-validation (10 folds)
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Evaluate using PR-AUC (average_precision)
cv_scores = cross_val_score(clf_pipeline, X_train, y_train, cv=cv, scoring='average_precision')
print(f"✅ Cross-validation PR-AUC: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}")

# Train final model on full training set
clf_pipeline.fit(X_train, y_train)

# CodeSnippet 18 (Updated)
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import precision_recall_curve, average_precision_score
import matplotlib.pyplot as plt

# Predictions
y_pred = clf_pipeline.predict(X_test)
y_proba = clf_pipeline.predict_proba(X_test)[:, 1]

# Reports
print(classification_report(y_test, y_pred))
print(f"✅ Test PR-AUC: {average_precision_score(y_test, y_proba):.3f}")

# Confusion matrix
ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot(cmap='Blues')
plt.title("Confusion Matrix – Machine Failure Prediction")
plt.show()

# Precision-Recall curve
precision, recall, thresholds = precision_recall_curve(y_test, y_proba)
plt.plot(recall, precision, color='blue')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision–Recall Curve (Test Set)')
plt.show()

# CodeSnippet 19 (Updated)
import joblib, json
from pathlib import Path
import pandas as pd

# Create artifacts directory
ARTIFACTS_DIR = Path("artifacts")
ARTIFACTS_DIR.mkdir(exist_ok=True)

# 1️⃣ Save model (pipeline completo con SMOTE + RandomForest)
# Compress using zlib (nativo en Python, no requiere instalación)
joblib.dump(clf_pipeline, ARTIFACTS_DIR / "model_failure_classifier.pkl", compress=('zlib', 3))

# 2️⃣ Save features list
with open(ARTIFACTS_DIR / "features_classifier.json", "w") as f:
    json.dump(features, f)

# 3️⃣ Save feature importances
# Access model dentro del pipeline
model_fitted = clf_pipeline.named_steps['model']
importances = pd.Series(model_fitted.feature_importances_, index=features)
importances.to_csv(ARTIFACTS_DIR / "feature_importances_classifier.csv", header=["importance"])

print("✅ Artifacts saved in ./artifacts:")
print("   - model_failure_classifier.pkl")
print("   - features_classifier.json")
print("   - feature_importances_classifier.csv")

data

from google.colab import sheets
sheet = sheets.InteractiveSheet(df=data)

